{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Hello My name is Will Dean. My background is in Statistics and have been working as a Data Scientist the last 4 years in the transportation and real estate industries. I enjoy working with geographical data. Most likely because it helps me forget about my Fernweh . I love to travel and figure out how the world works while talking to people in the process. I am currently interested in exploring different Bayesian models, specifically with the library PyMC . I find the software fun to use and very helpful for the problems I like to solve. Some of my other favorite python software recently is: PyYAML rich fastapi / typer (big fan of all the creator's work) geopandas As of late, I have been exploring python code design techniques to create easy-to-use APIs that can be easily extended. This YouTube Channel has been an inspiration for me. I love to learn and collaborate so feel free to connect with me ! I've been looking into freelancing and have some options posted here as well. For information about how this site was created, checkout my Blog Post here .","title":"Welcome"},{"location":"#hello","text":"My name is Will Dean. My background is in Statistics and have been working as a Data Scientist the last 4 years in the transportation and real estate industries. I enjoy working with geographical data. Most likely because it helps me forget about my Fernweh . I love to travel and figure out how the world works while talking to people in the process. I am currently interested in exploring different Bayesian models, specifically with the library PyMC . I find the software fun to use and very helpful for the problems I like to solve. Some of my other favorite python software recently is: PyYAML rich fastapi / typer (big fan of all the creator's work) geopandas As of late, I have been exploring python code design techniques to create easy-to-use APIs that can be easily extended. This YouTube Channel has been an inspiration for me. I love to learn and collaborate so feel free to connect with me ! I've been looking into freelancing and have some options posted here as well. For information about how this site was created, checkout my Blog Post here .","title":"Hello"},{"location":"tags/","text":"Tags Config Files Pydantic for Configs Documentation MkDocs and GitHub Pages Python My Favorite Python builtin: pathlib Pydantic for Configs MkDocs and GitHub Pages Standard Library My Favorite Python builtin: pathlib","title":"Tags"},{"location":"tags/#tags","text":"","title":"Tags"},{"location":"tags/#config-files","text":"Pydantic for Configs","title":"Config Files"},{"location":"tags/#documentation","text":"MkDocs and GitHub Pages","title":"Documentation"},{"location":"tags/#python","text":"My Favorite Python builtin: pathlib Pydantic for Configs MkDocs and GitHub Pages","title":"Python"},{"location":"tags/#standard-library","text":"My Favorite Python builtin: pathlib","title":"Standard Library"},{"location":"blog/","text":"Blog Posts Here are some things that I've found interesting and have written about.","title":"Blog Posts"},{"location":"blog/#blog-posts","text":"Here are some things that I've found interesting and have written about.","title":"Blog Posts"},{"location":"blog/posts/2022/pathlib/","tags":["Python","Standard Library"],"text":"My Favorite Python builtin: pathlib When working with python and data, file names quickly become a pain for many reasons. Firstly, files quickly add up. This could be from raw data, created processed data, config files, results including models and vizualizations. A lot more files are being worked with than initially thought, so not being organized can be quickly overwhelming. Secondly \u2014 and this may be a personal problem for me \u2014 start adding lengthy, hard-coded values for file names just becomes painful. Sometimes I even find it difficult to want to start working scripts. Of course, using strings can work, but this leads to working with many of the functions from the os and os.path modules. Who wants so many imports too? import os from os.path import join CURRENT_DIR : str = os . getcwd () file_name : str = \"my-data.csv\" data_file = join ( CURRENT_DIR , file_name ) print ( f \"The file { data_file } exists: { os . path . isfile ( data_file ) } \" ) Now, hand off your scripts to someone on a Window's machine. All your hard-coded paths aren't even in the right format now and I'm feeling total regrets for ever starting the project . Quick Start Using a pathlib.Path instance instead of a string is meant to be intuitive. That is, many actions like creating file, checking stats, relative location, etc are just methods of a Path instance. Other things like file name, suffix, or parents are attributes of the instance. Forget all the imports, working with Path object takes advantage of OOP design. When working in a python file, the __file__ variable can be utilized in order to find out where the current location is. No need to hard code or think about relative paths. current-file.py from pathlib import Path HERE = Path ( __file__ ) . parent # New file next to \"current-file.py\" new_file = HERE / \"new-file.txt\" if not new_file . exists (): new_file . touch () new_file . write_text ( \"Writing some text to the new file!\" ) RESULTS_DIR = HERE / \"results\" RESULTS_DIR . mkdir () # Some processing ... override : bool result_file = RESULTS_DIR / \"results-file.csv\" if results_file . exists () and not override : msg = \"We don't want to override this file!\" raise ValueError ( msg ) I find the interface very intuitive and cool thing here is that this will work on the machine regardless of the operating system. Using a data folder I often have a DATA_DIR constant for many of my projects which refers to a folder data off the root of my project. In the file system, that would look like this: my_module/ ... data/ ... README.md This is an easy setup and saves a lot of headaches in the future. my_module/utils.py from pathlib import Path DATA_DIR = Path ( __file__ ) if not DATA_DIR . exists (): DATA_DIR . mkdir () As long as I am working with my python module, I don't have to worry about much more than the file names I want. from my_module import utils file : Path = utils . DATA_DIR / \"raw\" / \"my-data.csv\" Additional folders I often extend this to include other folders I will likely have based on a project. This might be a folder data/raw , data/results , or even a configs dir. This depends on the project but all of this is with the goal of being as organized as possible from the start. I recently watched this related video on naming files and found it useful. Working with S3 locations I learned about this python package while working with S3 paths on AWS. I haven't personally used but I think it looks promising and would provide a similar enjoyable experience as the pathlib module. Conclusion Taming all the files you are working with is never an easy battle. However, I find using pathlib makes the process just a little more enjoyable.","title":"My Favorite Python builtin: pathlib"},{"location":"blog/posts/2022/pathlib/#my-favorite-python-builtin-pathlib","text":"When working with python and data, file names quickly become a pain for many reasons. Firstly, files quickly add up. This could be from raw data, created processed data, config files, results including models and vizualizations. A lot more files are being worked with than initially thought, so not being organized can be quickly overwhelming. Secondly \u2014 and this may be a personal problem for me \u2014 start adding lengthy, hard-coded values for file names just becomes painful. Sometimes I even find it difficult to want to start working scripts. Of course, using strings can work, but this leads to working with many of the functions from the os and os.path modules. Who wants so many imports too? import os from os.path import join CURRENT_DIR : str = os . getcwd () file_name : str = \"my-data.csv\" data_file = join ( CURRENT_DIR , file_name ) print ( f \"The file { data_file } exists: { os . path . isfile ( data_file ) } \" ) Now, hand off your scripts to someone on a Window's machine. All your hard-coded paths aren't even in the right format now and I'm feeling total regrets for ever starting the project .","title":"My Favorite Python builtin: pathlib"},{"location":"blog/posts/2022/pathlib/#quick-start","text":"Using a pathlib.Path instance instead of a string is meant to be intuitive. That is, many actions like creating file, checking stats, relative location, etc are just methods of a Path instance. Other things like file name, suffix, or parents are attributes of the instance. Forget all the imports, working with Path object takes advantage of OOP design. When working in a python file, the __file__ variable can be utilized in order to find out where the current location is. No need to hard code or think about relative paths. current-file.py from pathlib import Path HERE = Path ( __file__ ) . parent # New file next to \"current-file.py\" new_file = HERE / \"new-file.txt\" if not new_file . exists (): new_file . touch () new_file . write_text ( \"Writing some text to the new file!\" ) RESULTS_DIR = HERE / \"results\" RESULTS_DIR . mkdir () # Some processing ... override : bool result_file = RESULTS_DIR / \"results-file.csv\" if results_file . exists () and not override : msg = \"We don't want to override this file!\" raise ValueError ( msg ) I find the interface very intuitive and cool thing here is that this will work on the machine regardless of the operating system.","title":"Quick Start"},{"location":"blog/posts/2022/pathlib/#using-a-data-folder","text":"I often have a DATA_DIR constant for many of my projects which refers to a folder data off the root of my project. In the file system, that would look like this: my_module/ ... data/ ... README.md This is an easy setup and saves a lot of headaches in the future. my_module/utils.py from pathlib import Path DATA_DIR = Path ( __file__ ) if not DATA_DIR . exists (): DATA_DIR . mkdir () As long as I am working with my python module, I don't have to worry about much more than the file names I want. from my_module import utils file : Path = utils . DATA_DIR / \"raw\" / \"my-data.csv\"","title":"Using a data folder"},{"location":"blog/posts/2022/pathlib/#additional-folders","text":"I often extend this to include other folders I will likely have based on a project. This might be a folder data/raw , data/results , or even a configs dir. This depends on the project but all of this is with the goal of being as organized as possible from the start. I recently watched this related video on naming files and found it useful.","title":"Additional folders"},{"location":"blog/posts/2022/pathlib/#working-with-s3-locations","text":"I learned about this python package while working with S3 paths on AWS. I haven't personally used but I think it looks promising and would provide a similar enjoyable experience as the pathlib module.","title":"Working with S3 locations"},{"location":"blog/posts/2022/pathlib/#conclusion","text":"Taming all the files you are working with is never an easy battle. However, I find using pathlib makes the process just a little more enjoyable.","title":"Conclusion"},{"location":"blog/posts/2022/pydantic-configs/","tags":["Python","Config Files"],"text":"Using PyDantic for Configs Tip It might be helpful to know a bit about the pydantic library and its functionality. Luckily, the docs are very good. They are linked below. I discovered the pydantic library when I first started using Typer and FastAPI and quickly found the library very useful for other reasons. One use case I've found very helpful is when making config files for python scripts. There is clear benefit to using configs when writing python code: Variables can be changed without having to edit the python file itself. But by also using pydantic you get the additional benefits provided from the library. Clearly Define the Structure of the Config When working with configs, I often find it confusing to what all the possible supported settings are. However, if you define a Config class from the pydantic.BaseModel , you see clear structure for what you are working with. For instance, a project which is working with some input, output, and some additional configuration settings might look like this. from pydantic import BaseModel from pathlib import Path from typing import Dict , Any class Config ( BaseModel ): # Input input_location : Path # Result location and file name results_dir : Path results_file_name : str # Some additional configurations plotting_kwargs : Dict [ str , Any ] = {} This data can come from many sources but a YAML configuration file for this structure might look like this: config.yaml input_location : ./data/input_data.csv results_dir : ./results/ results_file_name : my_first_run.png plotting_kwargs : alpha : 0.5 By looking at the class structure, it is clear that some input and output information is required and additional plotting information is optional. Not only that, the user gets an understanding of what format the data should be in. Adding Hierarchy If the config starts to get too large, I've found splitting up into different sections to be very helpful. This can be sections for inputs, output, related setting, etc. A more organized YAML could look like this: input : file : some-input-file.csv output : base_dir : some-directory-to-save result_name : some-file-name.png In order to support this structure, each one of the sections would be its own class in the defined pydantic model. class InputSetting ( BaseModel ): file : Path class OutputSetting ( BaseModel ): base_dir : Path results_name : str class Config ( BaseModel ): \"\"\"Class version of the full config file\"\"\" input : InputSettings output : OutputSettings This allows for like items to be broken up in a logical way and support complicated configuration options. Additional Functionality Since all of these configs items are python classes, additional functionality can be added to them with methods and attributes. This add to the cohesion of the code by putting similiar methods together. For instance, if there is some type of connection settings, and adding additional functionality to load data might be helpful to group together. import pandas as pd class DataBaseSettings ( BaseModel ): schema : str table : str def is_connected ( self ) -> bool : \"\"\"Determine if connection exists.\"\"\" def read_table ( self ) -> pd . DataFrame : \"\"\"Return the table from the database.\"\"\" class Config ( BaseModel ): database : DataBaseSettings Generalization and Extensions Because of the powerful structure parsing of pydantics, we can extend our configs very easily by providing abstractions to our data models. For instance, if multiple different data sources want to be supported, then that can be reflected in our configuration. class CSVSettings ( BaseModel ): \"\"\"Data source that is csv format.\"\"\" location : Path def read_table ( self ) -> pd . DataFrame : \"\"\"Read from csv file.\"\"\" class Config ( BaseModel ): \"\"\"Generalized configuration.\"\"\" source : CSVSettings | DataBaseSettings Because pydantic will be able to understand these structural differences, we are able to change our config file accordingly. --- source : location : data/some-local-data.csv --- source : schema : my-schema table : my-table When the config is parsed into an instance, the common interface can be leveraged in the code while also providing flexibility in the settings. Reusability If there are multiple configuration files required for a project, there will often be overlapping configuration elements. By structuring the code in the hierarchical manner , different classes can be reused in order to simplify our interface. class RunConfig ( BaseModel ): \"\"\"Running and saving off a model.\"\"\" input_settings : InputSettings model_settings : ModelSettings results : ResultsLocation class InterpretationConfig ( BaseModel ): \"\"\"Loading and interpreting model.\"\"\" results : ResultsLocation The ResultsLocation class might be useful in multiple configuration files here because it is used to both save and load data. Limiting Options If you want to limit options a variable can take, an enum.Enum type can be used to enforce only a set number of choices. This provides some checking at config parsing time which can give you some quick feedback. from enum import Enum class Difficulties ( Enum ): EASY : str = \"easy\" MEDIUM : str = \"medium\" HARD : str = \"hard\" class Config ( BaseModel ): difficulty : Difficulties Or like the other example above , a union of types can be expressed. Additional Validation Pydantic provides a bunch of additional data validation which can provide some runtime checks to your configuration. If you are used to using dataclasses too, the dataclasses submodule can be very helpful in order to add some additional checks on the configs at runtime as well. from pydantic.dataclasses import dataclass @dataclass class ResultSettings : results_dir : Path file_name : str override : bool = False def __post_init__ ( self ) -> None : if not self . results_dir . exists (): self . results_dir . mkdir () save_location = self . results_dir / self . file_name if save_location . exists () and not override : msg = f \"The results already exists. Not running { save_location } \" raise ValueError ( msg ) Class Implementation I often add a lightweight class implementation when working with YAML configs. The goal here is to add an additional method to the pydantic BaseModel in order to easily load different config files. yaml_base_model.py from pydantic import BaseModel import yaml from pathlib import Path class YamlBaseModel ( BaseModel ) @classmethod def from_yaml ( cls , file : str | Path ) -> YamlBaseModel : file = Path ( file ) with open ( file , \"r\" ) as f : data = yaml . safe_load ( f ) return cls . parse_obj ( data ) Then when defining a config file, this will be the class inherited from. Making it clear which define the structure of config files and which are just parts of a larger configuration. class ModelSettings ( BaseModel ): \"\"\"Won't be a config file but will be part of some larger configuration.\"\"\" folds : int method : str ... class RunConfig ( YamlBaseModel ): \"\"\"Some YAML config file will have this structure.\"\"\" input : InputSettings model_settings : ModelSettings This allows for easy construction of a config object and can be used accordingly. run_script.py if __name__ == \"__main__\" : config = RunConfig . from_yaml ( \"./configs/run-config.yaml\" ) data = config . input . load_data () Find the gist of this here with an additional example. Prefer TOML Configs ? Can imagine similar support for TOML configs (especially with latest support in python 3.11). Same goes with some additional formats too. Alternative Comparison I have an example where: Some data will be loaded in Some model with configuration is loaded in The model is trained and saves: Logging information Trained model The three implementations will go from worst to best. 1. Hard Coding Constants This is the worst case implementation since any changes happen to happen in the python file itself. Not only that, but some of the hard-coded values are at the end of the file. That could be hard to sift through if it was a larger file! from my_module import utils , model , data if __name__ == \"__main__\" : df = data . load_data ( utils . RAW_DATA_DIR / \"training-data.csv\" ) my_model_config = { ... } my_model = model . MyModel ( ** my_model_config ) my_model . train ( df ) my_model . save_logs ( utils . LOGGING_DIR / \"logging.txt\" ) my_model . save_model ( utils . MODEL_DIR / \"my-model.pkl\" ) 2. Using Unstructured Configs This introduces a yaml config file which separates all the changing variables from the python file itself. However, it is not totally clear what are all the options available. I do think this is a large improvement though! config.yaml training_data : training-data.csv model_config : folds : 5 random_seed : 42 ... logging_name : logging.txt model_name : my-model.pkl from typing import Dict , Any if __name__ == \"__main__\" : config : Dict [ str , Any ] = utils . load_config ( \"config.yaml\" ) df = data . load_data ( utils . RAW_DATA_DIR / config [ \"training_data\" ] ) my_model = model . MyModel ( ** config [ \"model_config\" ]) my_model . train ( df ) my_model . save_logs ( utils . LOGGING_DIR / config [ \"logging_name\" ] ) my_model . save_model ( utils . MODEL_DIR / config [ \"model_name\" ] ) 3. Config with Pydantic This might be a way to implement with pydantic. my_module/config.py from my_module import utils class Source : training_data : str raw_data : Path = utils . RAW_DATA_DIR def load_data ( self ) -> pd . DataFrame : ... class ModelConfig ( BaseModel ): folds : int = 5 random_seed : int = 42 def slugify_config ( self , file_base : Path ) -> str : \"\"\"Helper for file naming.\"\"\" class Artifacts ( BaseModel ): logging_name : str model_name : str logging_dir : Path = utils . LOGGING_DIR model_dir : Path = utils . MODEL_DIR class Config ( YamlBaseModel ): training_source : Source model_config : ModelConfig model_artifacts : Artifacts config.yaml training_source : training_data : training-data.csv model_config : folds : 10 random_seed : 1 artifacts : logging_name : logging.txt model_name : my-model.pkl if __name__ == \"__main__\" : config : Config = Config . from_yaml ( \"config.yaml\" ) df = config . source . load_data () my_model = model . MyModel ( config . model_config ) my_model . fit ( df ) my_model . save_artifacts ( config . model_config , config . model_artifacts ) This is clearly the most explicit version of the three. However, there are a lot of benefits for doing so. Clearly defined configuration leads to: Known functionality from class definitions Related functionality sticks together Shorter code in script because: OOP structuring Ability to work with default values Able to be extended if desired like: Better file naming using config information Conclusion Overall, I've found defining configs with pydantic in mind very useful. It can be super quick to do, provide a lot more structure and understanding to the config settings, and leverage the powerful parsing validation from the library. Give it a try!","title":"Pydantic for Configs"},{"location":"blog/posts/2022/pydantic-configs/#using-pydantic-for-configs","text":"Tip It might be helpful to know a bit about the pydantic library and its functionality. Luckily, the docs are very good. They are linked below. I discovered the pydantic library when I first started using Typer and FastAPI and quickly found the library very useful for other reasons. One use case I've found very helpful is when making config files for python scripts. There is clear benefit to using configs when writing python code: Variables can be changed without having to edit the python file itself. But by also using pydantic you get the additional benefits provided from the library.","title":"Using PyDantic for Configs"},{"location":"blog/posts/2022/pydantic-configs/#clearly-define-the-structure-of-the-config","text":"When working with configs, I often find it confusing to what all the possible supported settings are. However, if you define a Config class from the pydantic.BaseModel , you see clear structure for what you are working with. For instance, a project which is working with some input, output, and some additional configuration settings might look like this. from pydantic import BaseModel from pathlib import Path from typing import Dict , Any class Config ( BaseModel ): # Input input_location : Path # Result location and file name results_dir : Path results_file_name : str # Some additional configurations plotting_kwargs : Dict [ str , Any ] = {} This data can come from many sources but a YAML configuration file for this structure might look like this: config.yaml input_location : ./data/input_data.csv results_dir : ./results/ results_file_name : my_first_run.png plotting_kwargs : alpha : 0.5 By looking at the class structure, it is clear that some input and output information is required and additional plotting information is optional. Not only that, the user gets an understanding of what format the data should be in.","title":"Clearly Define the Structure of the Config"},{"location":"blog/posts/2022/pydantic-configs/#adding-hierarchy","text":"If the config starts to get too large, I've found splitting up into different sections to be very helpful. This can be sections for inputs, output, related setting, etc. A more organized YAML could look like this: input : file : some-input-file.csv output : base_dir : some-directory-to-save result_name : some-file-name.png In order to support this structure, each one of the sections would be its own class in the defined pydantic model. class InputSetting ( BaseModel ): file : Path class OutputSetting ( BaseModel ): base_dir : Path results_name : str class Config ( BaseModel ): \"\"\"Class version of the full config file\"\"\" input : InputSettings output : OutputSettings This allows for like items to be broken up in a logical way and support complicated configuration options.","title":"Adding Hierarchy"},{"location":"blog/posts/2022/pydantic-configs/#additional-functionality","text":"Since all of these configs items are python classes, additional functionality can be added to them with methods and attributes. This add to the cohesion of the code by putting similiar methods together. For instance, if there is some type of connection settings, and adding additional functionality to load data might be helpful to group together. import pandas as pd class DataBaseSettings ( BaseModel ): schema : str table : str def is_connected ( self ) -> bool : \"\"\"Determine if connection exists.\"\"\" def read_table ( self ) -> pd . DataFrame : \"\"\"Return the table from the database.\"\"\" class Config ( BaseModel ): database : DataBaseSettings","title":"Additional Functionality"},{"location":"blog/posts/2022/pydantic-configs/#generalization-and-extensions","text":"Because of the powerful structure parsing of pydantics, we can extend our configs very easily by providing abstractions to our data models. For instance, if multiple different data sources want to be supported, then that can be reflected in our configuration. class CSVSettings ( BaseModel ): \"\"\"Data source that is csv format.\"\"\" location : Path def read_table ( self ) -> pd . DataFrame : \"\"\"Read from csv file.\"\"\" class Config ( BaseModel ): \"\"\"Generalized configuration.\"\"\" source : CSVSettings | DataBaseSettings Because pydantic will be able to understand these structural differences, we are able to change our config file accordingly. --- source : location : data/some-local-data.csv --- source : schema : my-schema table : my-table When the config is parsed into an instance, the common interface can be leveraged in the code while also providing flexibility in the settings.","title":"Generalization and Extensions"},{"location":"blog/posts/2022/pydantic-configs/#reusability","text":"If there are multiple configuration files required for a project, there will often be overlapping configuration elements. By structuring the code in the hierarchical manner , different classes can be reused in order to simplify our interface. class RunConfig ( BaseModel ): \"\"\"Running and saving off a model.\"\"\" input_settings : InputSettings model_settings : ModelSettings results : ResultsLocation class InterpretationConfig ( BaseModel ): \"\"\"Loading and interpreting model.\"\"\" results : ResultsLocation The ResultsLocation class might be useful in multiple configuration files here because it is used to both save and load data.","title":"Reusability"},{"location":"blog/posts/2022/pydantic-configs/#limiting-options","text":"If you want to limit options a variable can take, an enum.Enum type can be used to enforce only a set number of choices. This provides some checking at config parsing time which can give you some quick feedback. from enum import Enum class Difficulties ( Enum ): EASY : str = \"easy\" MEDIUM : str = \"medium\" HARD : str = \"hard\" class Config ( BaseModel ): difficulty : Difficulties Or like the other example above , a union of types can be expressed.","title":"Limiting Options"},{"location":"blog/posts/2022/pydantic-configs/#additional-validation","text":"Pydantic provides a bunch of additional data validation which can provide some runtime checks to your configuration. If you are used to using dataclasses too, the dataclasses submodule can be very helpful in order to add some additional checks on the configs at runtime as well. from pydantic.dataclasses import dataclass @dataclass class ResultSettings : results_dir : Path file_name : str override : bool = False def __post_init__ ( self ) -> None : if not self . results_dir . exists (): self . results_dir . mkdir () save_location = self . results_dir / self . file_name if save_location . exists () and not override : msg = f \"The results already exists. Not running { save_location } \" raise ValueError ( msg )","title":"Additional Validation"},{"location":"blog/posts/2022/pydantic-configs/#class-implementation","text":"I often add a lightweight class implementation when working with YAML configs. The goal here is to add an additional method to the pydantic BaseModel in order to easily load different config files. yaml_base_model.py from pydantic import BaseModel import yaml from pathlib import Path class YamlBaseModel ( BaseModel ) @classmethod def from_yaml ( cls , file : str | Path ) -> YamlBaseModel : file = Path ( file ) with open ( file , \"r\" ) as f : data = yaml . safe_load ( f ) return cls . parse_obj ( data ) Then when defining a config file, this will be the class inherited from. Making it clear which define the structure of config files and which are just parts of a larger configuration. class ModelSettings ( BaseModel ): \"\"\"Won't be a config file but will be part of some larger configuration.\"\"\" folds : int method : str ... class RunConfig ( YamlBaseModel ): \"\"\"Some YAML config file will have this structure.\"\"\" input : InputSettings model_settings : ModelSettings This allows for easy construction of a config object and can be used accordingly. run_script.py if __name__ == \"__main__\" : config = RunConfig . from_yaml ( \"./configs/run-config.yaml\" ) data = config . input . load_data () Find the gist of this here with an additional example. Prefer TOML Configs ? Can imagine similar support for TOML configs (especially with latest support in python 3.11). Same goes with some additional formats too.","title":"Class Implementation"},{"location":"blog/posts/2022/pydantic-configs/#alternative-comparison","text":"I have an example where: Some data will be loaded in Some model with configuration is loaded in The model is trained and saves: Logging information Trained model The three implementations will go from worst to best.","title":"Alternative Comparison"},{"location":"blog/posts/2022/pydantic-configs/#1-hard-coding-constants","text":"This is the worst case implementation since any changes happen to happen in the python file itself. Not only that, but some of the hard-coded values are at the end of the file. That could be hard to sift through if it was a larger file! from my_module import utils , model , data if __name__ == \"__main__\" : df = data . load_data ( utils . RAW_DATA_DIR / \"training-data.csv\" ) my_model_config = { ... } my_model = model . MyModel ( ** my_model_config ) my_model . train ( df ) my_model . save_logs ( utils . LOGGING_DIR / \"logging.txt\" ) my_model . save_model ( utils . MODEL_DIR / \"my-model.pkl\" )","title":"1. Hard Coding Constants"},{"location":"blog/posts/2022/pydantic-configs/#2-using-unstructured-configs","text":"This introduces a yaml config file which separates all the changing variables from the python file itself. However, it is not totally clear what are all the options available. I do think this is a large improvement though! config.yaml training_data : training-data.csv model_config : folds : 5 random_seed : 42 ... logging_name : logging.txt model_name : my-model.pkl from typing import Dict , Any if __name__ == \"__main__\" : config : Dict [ str , Any ] = utils . load_config ( \"config.yaml\" ) df = data . load_data ( utils . RAW_DATA_DIR / config [ \"training_data\" ] ) my_model = model . MyModel ( ** config [ \"model_config\" ]) my_model . train ( df ) my_model . save_logs ( utils . LOGGING_DIR / config [ \"logging_name\" ] ) my_model . save_model ( utils . MODEL_DIR / config [ \"model_name\" ] )","title":"2. Using Unstructured Configs"},{"location":"blog/posts/2022/pydantic-configs/#3-config-with-pydantic","text":"This might be a way to implement with pydantic. my_module/config.py from my_module import utils class Source : training_data : str raw_data : Path = utils . RAW_DATA_DIR def load_data ( self ) -> pd . DataFrame : ... class ModelConfig ( BaseModel ): folds : int = 5 random_seed : int = 42 def slugify_config ( self , file_base : Path ) -> str : \"\"\"Helper for file naming.\"\"\" class Artifacts ( BaseModel ): logging_name : str model_name : str logging_dir : Path = utils . LOGGING_DIR model_dir : Path = utils . MODEL_DIR class Config ( YamlBaseModel ): training_source : Source model_config : ModelConfig model_artifacts : Artifacts config.yaml training_source : training_data : training-data.csv model_config : folds : 10 random_seed : 1 artifacts : logging_name : logging.txt model_name : my-model.pkl if __name__ == \"__main__\" : config : Config = Config . from_yaml ( \"config.yaml\" ) df = config . source . load_data () my_model = model . MyModel ( config . model_config ) my_model . fit ( df ) my_model . save_artifacts ( config . model_config , config . model_artifacts ) This is clearly the most explicit version of the three. However, there are a lot of benefits for doing so. Clearly defined configuration leads to: Known functionality from class definitions Related functionality sticks together Shorter code in script because: OOP structuring Ability to work with default values Able to be extended if desired like: Better file naming using config information","title":"3. Config with Pydantic"},{"location":"blog/posts/2022/pydantic-configs/#conclusion","text":"Overall, I've found defining configs with pydantic in mind very useful. It can be super quick to do, provide a lot more structure and understanding to the config settings, and leverage the powerful parsing validation from the library. Give it a try!","title":"Conclusion"},{"location":"blog/posts/2022/site-setup/","tags":["Python","Documentation"],"text":"MkDocs and GitHub Pages This website was created using MkDocs , surrounding python packages like mkdocs-material , and is served with GitHub pages . About MkDocs and its plugins The MkDocs library makes it easy to create documentation from just markdown and YAML files. With just a few commands, you can quickly iterate with your content and make some great looking webpages. There is also a handful plugin libraries for MkDocs that allow for additional customization. For instance, the theme used here is from the mkdocs-material package. Makes it so easy to have a good looking site on all platforms (especially for people like me who don't make user interfaces often ). Creating the Content and Theme MkDocs really makes it so easy to set up a page. The Getting Started Section allows you to get started. The simpliest project setup will just be two files: The themes and capabilities were inspired from the mkdocs-material site and exploring its mkdocs.yml helped implement mine. Serving with GitHub Pages GitHub allows you to set up a site for free. If the repo is named <username>.github.io , then it will be hosted at https://<username>.github.io . Tip If you deploy with GitHub pages in any other repo, the docs with be hosted at https://<username>.github.io/<repo-name> . Super cool and would like to use in the future to make quick project documentation! All the code to create this site is on my GitHub here . GitHub Action The mkdocs-material documentation has the steps in order to set up your GitHub Action for deploy. Those steps are found here . GitHub Page Settings I had some hiccups while setting up the site. Initially, only my README was being served at https://wd60622.github.io . However, the default \"Deploy from a branch\" setting in the GitHub Pages section was on the main branch which only had the README. Note Running mkdocs gh-deploy pushes all the html files to gh-pages branch in my repo so that branch needed to be selected in the Settings. Below are Settings section that worked for my deployment. Helpful Links I found these links helpful while setting up this site and writing this post. MkDocs MkDocs Material GitHub Pages","title":"MkDocs and GitHub Pages"},{"location":"blog/posts/2022/site-setup/#mkdocs-and-github-pages","text":"This website was created using MkDocs , surrounding python packages like mkdocs-material , and is served with GitHub pages .","title":"MkDocs and GitHub Pages"},{"location":"blog/posts/2022/site-setup/#about-mkdocs-and-its-plugins","text":"The MkDocs library makes it easy to create documentation from just markdown and YAML files. With just a few commands, you can quickly iterate with your content and make some great looking webpages. There is also a handful plugin libraries for MkDocs that allow for additional customization. For instance, the theme used here is from the mkdocs-material package. Makes it so easy to have a good looking site on all platforms (especially for people like me who don't make user interfaces often ).","title":"About MkDocs and its plugins"},{"location":"blog/posts/2022/site-setup/#creating-the-content-and-theme","text":"MkDocs really makes it so easy to set up a page. The Getting Started Section allows you to get started. The simpliest project setup will just be two files: The themes and capabilities were inspired from the mkdocs-material site and exploring its mkdocs.yml helped implement mine.","title":"Creating the Content and Theme"},{"location":"blog/posts/2022/site-setup/#serving-with-github-pages","text":"GitHub allows you to set up a site for free. If the repo is named <username>.github.io , then it will be hosted at https://<username>.github.io . Tip If you deploy with GitHub pages in any other repo, the docs with be hosted at https://<username>.github.io/<repo-name> . Super cool and would like to use in the future to make quick project documentation! All the code to create this site is on my GitHub here .","title":"Serving with GitHub Pages"},{"location":"blog/posts/2022/site-setup/#github-action","text":"The mkdocs-material documentation has the steps in order to set up your GitHub Action for deploy. Those steps are found here .","title":"GitHub Action"},{"location":"blog/posts/2022/site-setup/#github-page-settings","text":"I had some hiccups while setting up the site. Initially, only my README was being served at https://wd60622.github.io . However, the default \"Deploy from a branch\" setting in the GitHub Pages section was on the main branch which only had the README. Note Running mkdocs gh-deploy pushes all the html files to gh-pages branch in my repo so that branch needed to be selected in the Settings. Below are Settings section that worked for my deployment.","title":"GitHub Page Settings"},{"location":"blog/posts/2022/site-setup/#helpful-links","text":"I found these links helpful while setting up this site and writing this post. MkDocs MkDocs Material GitHub Pages","title":"Helpful Links"},{"location":"blog/posts/2023/more-to-come/","text":"More to Come ... Soon I have some projects I've been working on recently... more to come.","title":"More to Come ... Soon"},{"location":"blog/posts/2023/more-to-come/#more-to-come-soon","text":"I have some projects I've been working on recently... more to come.","title":"More to Come ... Soon"},{"location":"resources/","text":"Favorite Resources Tools Notion I started using Notion for organizing my life. I find it is a great tool for personal projects, journaling, and all things above. There is so many customization options to it out of the box and the features keep on improving. It is also very awesome that it can be used on all platforms. YouTube ArjanCodes This guy puts out some high quality content for python programming. I've really enjoyed all of his material and he posts very consistently. I've found my coding style to be heavily influenced by him and I have found many resources because of him.","title":"Favorite Resources"},{"location":"resources/#favorite-resources","text":"","title":"Favorite Resources"},{"location":"resources/#tools","text":"","title":"Tools"},{"location":"resources/#notion","text":"I started using Notion for organizing my life. I find it is a great tool for personal projects, journaling, and all things above. There is so many customization options to it out of the box and the features keep on improving. It is also very awesome that it can be used on all platforms.","title":"Notion"},{"location":"resources/#youtube","text":"","title":"YouTube"},{"location":"resources/#arjancodes","text":"This guy puts out some high quality content for python programming. I've really enjoyed all of his material and he posts very consistently. I've found my coding style to be heavily influenced by him and I have found many resources because of him.","title":"ArjanCodes"},{"location":"tags/","text":"Tags Config Files Pydantic for Configs Documentation MkDocs and GitHub Pages Python My Favorite Python builtin: pathlib Pydantic for Configs MkDocs and GitHub Pages Standard Library My Favorite Python builtin: pathlib","title":"Tags"},{"location":"tags/#tags","text":"","title":"Tags"},{"location":"tags/#config-files","text":"Pydantic for Configs","title":"Config Files"},{"location":"tags/#documentation","text":"MkDocs and GitHub Pages","title":"Documentation"},{"location":"tags/#python","text":"My Favorite Python builtin: pathlib Pydantic for Configs MkDocs and GitHub Pages","title":"Python"},{"location":"tags/#standard-library","text":"My Favorite Python builtin: pathlib","title":"Standard Library"}]}