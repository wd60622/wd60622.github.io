{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Hello","text":"<p>My name is Will Dean. My background is in Statistics and have been working as a Data Scientist the last 4 years in the transportation and real estate industries. </p> <p>I enjoy working with geographical data. Most likely because it helps me forget about my Fernweh. I love to travel and figure out how the world works while talking to people in the process. </p> <p>I am currently interested in exploring different Bayesian models, specifically with the library <code>PyMC</code>. I find the software fun to use and very helpful for the problems I like to solve. </p> <p>I love to learn and collaborate so feel free to connect with me! I've been looking into freelancing and have some options posted here as well. </p> <p></p>"},{"location":"contact/","title":"Contact Me","text":"<p>If you'd like to get in touch, please reach out on LinkedIn.</p>"},{"location":"open-source/","title":"Open Source Contributions","text":"<p>I really enjoy tinkering with code and contributing to open source projects. Here are some of the repositories I have created and contributed to.</p> <p>Created by me:  </p> <ul> <li>latent-calendar: Analyze and model weekly calendar distributions using latent components</li> <li>conjugate-models: A Python package for Bayesian Conjugate Models</li> <li>pandas-bootstrap: A Python package for bootstrapping in Pandas</li> <li>lyft-bikes: A Python client of Lyft's Bike Share Data</li> </ul> <p>Contributed to:</p> <ul> <li>PyMC: Various issues and Pull Requests</li> <li>PyMC-Marketing: Various issues and Pull Requests</li> <li>Small features, bug fix, of documentation PRs <ul> <li>bambi</li> <li>formulae</li> <li>aesara</li> <li>mkdocs-git-revision-date-localized-plugin</li> <li>timeseers</li> <li>folium</li> <li>branca</li> </ul> </li> </ul>"},{"location":"resources/","title":"Favorite Resources","text":""},{"location":"resources/#tools","title":"Tools","text":""},{"location":"resources/#notion","title":"Notion","text":"<p>I started using Notion for organizing my life. I find it is a great tool for personal projects, journaling, and all things above. </p> <p>There is so many customization options to it out of the box and the features keep on improving. </p> <p>It is also very awesome that it can be used on all platforms.</p>"},{"location":"resources/#youtube","title":"YouTube","text":""},{"location":"resources/#arjancodes","title":"ArjanCodes","text":"<p>This guy puts out some high quality content for python programming. I've really enjoyed all of his material and he posts very consistently. </p> <p>I've found my coding style to be heavily influenced by him and I have found many resources because of him.</p>"},{"location":"blog/","title":"Blog Posts","text":"<p>Here are some things that I've found interesting and have written about.</p>"},{"location":"blog/#bayesian-statistics","title":"Bayesian Statistics","text":"<ul> <li>Conjugate Priors</li> </ul>"},{"location":"blog/#config-files","title":"Config Files","text":"<ul> <li>Pydantic for Configs</li> </ul>"},{"location":"blog/#data-analysis","title":"Data Analysis","text":"<ul> <li>Extending Pandas</li> <li>Iteration Pattern</li> </ul>"},{"location":"blog/#design-patterns","title":"Design Patterns","text":"<ul> <li>Iteration Pattern</li> </ul>"},{"location":"blog/#documentation","title":"Documentation","text":"<ul> <li>MkDocs and GitHub Pages</li> </ul>"},{"location":"blog/#pandas","title":"Pandas","text":"<ul> <li>Extending Pandas</li> </ul>"},{"location":"blog/#python","title":"Python","text":"<ul> <li>My Favorite Python builtin: pathlib</li> <li>Pydantic for Configs</li> <li>MkDocs and GitHub Pages</li> <li>Conjugate Priors</li> <li>Extending Pandas</li> <li>Iteration Pattern</li> </ul>"},{"location":"blog/#standard-library","title":"Standard Library","text":"<ul> <li>My Favorite Python builtin: pathlib</li> </ul>"},{"location":"blog/posts/2022/pathlib/","title":"My Favorite Python builtin: pathlib","text":"<p>When working with python and data, file names quickly become a pain for many reasons. </p> <p>Firstly, files quickly add up. This could be from raw data, created processed data, config files, results including models and vizualizations. A lot more files are being worked with than initially thought, so not being organized can be quickly overwhelming.</p> <p>Secondly \u2014 and this may be a personal problem for me \u2014 start adding lengthy, hard-coded values for file names just becomes painful. Sometimes I even find it difficult to want to start working scripts.</p> <p>Of course, using strings can work, but this leads to working with many of the functions from the <code>os</code> and <code>os.path</code> modules. Who wants so many imports too? </p> <pre><code>import os \nfrom os.path import join\nCURRENT_DIR: str = os.getcwd()\nfile_name: str = \"my-data.csv\"\ndata_file = join(CURRENT_DIR, file_name)\nprint(f\"The file {data_file} exists: {os.path.isfile(data_file)}\")\n</code></pre> <p>Now, hand off your scripts to someone on a Window's machine. All your hard-coded paths aren't even in the right format now and I'm feeling total regrets for ever starting the project .</p>","tags":["Python","Standard Library"]},{"location":"blog/posts/2022/pathlib/#quick-start","title":"Quick Start","text":"<p>Using a <code>pathlib.Path</code> instance instead of a string is meant to be intuitive. </p> <p>That is, many actions like creating file, checking stats, relative location, etc are just methods of a <code>Path</code> instance. Other things like file name, suffix, or parents are attributes of the instance. Forget all the imports, working with <code>Path</code> object takes advantage of OOP design.</p> <p>When working in a python file, the <code>__file__</code> variable can be utilized in order to find out where the current location is. No need to hard code or think about relative paths.</p> current-file.py<pre><code>from pathlib import Path \nHERE = Path(__file__).parent\n# New file next to \"current-file.py\"\nnew_file = HERE / \"new-file.txt\"\nif not new_file.exists(): \nnew_file.touch()\nnew_file.write_text(\"Writing some text to the new file!\")\nRESULTS_DIR = HERE / \"results\"\nRESULTS_DIR.mkdir()\n# Some processing\n...\noverride: bool\nresult_file = RESULTS_DIR / \"results-file.csv\"\nif results_file.exists() and not override: \nmsg = \"We don't want to override this file!\"\nraise ValueError(msg)\n</code></pre> <p>I find the interface very intuitive and cool thing here is that this will work on the machine regardless of the operating system. </p>","tags":["Python","Standard Library"]},{"location":"blog/posts/2022/pathlib/#using-a-data-folder","title":"Using a data folder","text":"<p>I often have a <code>DATA_DIR</code> constant for many of my projects which refers to a folder <code>data</code> off the root of my project. </p> <p>In the file system, that would look like this:</p> <pre><code>my_module/\n    ...\ndata/\n    ...\nREADME.md\n</code></pre> <p>This is an easy setup and saves a lot of headaches in the future.</p> my_module/utils.py<pre><code>from pathlib import Path\nDATA_DIR = Path(__file__)\nif not DATA_DIR.exists(): \nDATA_DIR.mkdir()\n</code></pre> <p>As long as I am working with my python module, I don't have to worry about much more than the file names I want.</p> <pre><code>from my_module import utils\nfile: Path = utils.DATA_DIR / \"raw\" / \"my-data.csv\"\n</code></pre>","tags":["Python","Standard Library"]},{"location":"blog/posts/2022/pathlib/#additional-folders","title":"Additional folders","text":"<p>I often extend this to include other folders I will likely have based on a project. This might be a folder <code>data/raw</code>, <code>data/results</code>, or even a <code>configs</code> dir.</p> <p>This depends on the project but all of this is with the goal of being as organized as possible from the start. </p> <p>I recently watched this related video on naming files and found it useful. </p>","tags":["Python","Standard Library"]},{"location":"blog/posts/2022/pathlib/#working-with-s3-locations","title":"Working with S3 locations","text":"<p>I learned about this python package while working with S3 paths on AWS. I haven't personally used but I think it looks promising and would provide a similar enjoyable experience as the <code>pathlib</code> module.</p>","tags":["Python","Standard Library"]},{"location":"blog/posts/2022/pathlib/#conclusion","title":"Conclusion","text":"<p>Taming all the files you are working with is never an easy battle. However, I find using <code>pathlib</code> makes the process just a little more enjoyable.</p>","tags":["Python","Standard Library"]},{"location":"blog/posts/2022/pydantic-configs/","title":"Using Pydantic for Configs","text":"<p>Tip</p> <p>It might be helpful to know a bit about the pydantic library and its functionality. Luckily, the docs are very good. They are linked below.</p> <p>I discovered the pydantic library when I first started using Typer and FastAPI and quickly found the library very useful for other reasons.</p> <p>One use case I've found very helpful is when making config files for python scripts. </p> <p>There is clear benefit to using configs when writing python code: Variables can be changed without having to edit the python file itself. But by also using pydantic you get the additional benefits provided from the library. </p>","tags":["Python","Config Files"]},{"location":"blog/posts/2022/pydantic-configs/#clearly-define-the-structure-of-the-config","title":"Clearly Define the Structure of the Config","text":"<p>When working with configs, I often find it confusing to what all the possible supported settings are. However, if you define a <code>Config</code> class from the <code>pydantic.BaseModel</code>, you see clear structure for what you are working with. </p> <p>For instance, a project which is working with some input, output, and some additional configuration settings might look like this.</p> <pre><code>from pydantic import BaseModel\nfrom pathlib import Path\nfrom typing import Dict, Any\nclass Config(BaseModel):\n# Input  \ninput_location: Path\n# Result location and file name\nresults_dir: Path\nresults_file_name: str\n# Some additional configurations\nplotting_kwargs: Dict[str, Any] = {}\n</code></pre> <p>This data can come from many sources but a YAML configuration file for this structure might look like this:</p> config.yaml<pre><code>input_location: ./data/input_data.csv\nresults_dir: ./results/\nresults_file_name: my_first_run.png\nplotting_kwargs: alpha: 0.5\n</code></pre> <p>By looking at the class structure, it is clear that some input and output information is required and additional plotting information is optional. Not only that, the user gets an understanding of what format the data should be in.</p>","tags":["Python","Config Files"]},{"location":"blog/posts/2022/pydantic-configs/#adding-hierarchy","title":"Adding Hierarchy","text":"<p>If the config starts to get too large, I've found splitting up into different sections to be very helpful. This can be sections for inputs, output, related setting, etc. A more organized YAML could look like this:</p> <pre><code>input: file: some-input-file.csv\noutput: base_dir: some-directory-to-save\nresult_name: some-file-name.png\n</code></pre> <p>In order to support this structure, each one of the sections would be its own class in the defined pydantic model. </p> <pre><code>class InputSetting(BaseModel): \nfile: Path \nclass OutputSetting(BaseModel): \nbase_dir: Path\nresults_name: str \nclass Config(BaseModel): \n\"\"\"Class version of the full config file\"\"\"\ninput: InputSettings\noutput: OutputSettings\n</code></pre> <p>This allows for like items to be broken up in a logical way and support complicated configuration options.</p>","tags":["Python","Config Files"]},{"location":"blog/posts/2022/pydantic-configs/#additional-functionality","title":"Additional Functionality","text":"<p>Since all of these configs items are python classes, additional functionality can be added to them with methods and attributes. This add to the cohesion of the code by putting similiar methods together.</p> <p>For instance, if there is some type of connection settings, and adding additional functionality to load data might be helpful to group together. </p> <pre><code>import pandas as pd\nclass DataBaseSettings(BaseModel): \nschema: str \ntable: str \ndef is_connected(self) -&gt; bool: \n\"\"\"Determine if connection exists.\"\"\"\ndef read_table(self) -&gt; pd.DataFrame: \n\"\"\"Return the table from the database.\"\"\"\nclass Config(BaseModel): \ndatabase: DataBaseSettings\n</code></pre>","tags":["Python","Config Files"]},{"location":"blog/posts/2022/pydantic-configs/#generalization-and-extensions","title":"Generalization and Extensions","text":"<p>Because of the powerful structure parsing of pydantics, we can extend our configs very easily by providing abstractions to our data models.</p> <p>For instance, if multiple different data sources want to be supported, then that can be reflected in our configuration.</p> <pre><code>class CSVSettings(BaseModel): \n\"\"\"Data source that is csv format.\"\"\"\nlocation: Path\ndef read_table(self) -&gt; pd.DataFrame: \n\"\"\"Read from csv file.\"\"\"\nclass Config(BaseModel): \n\"\"\"Generalized configuration.\"\"\"\nsource: CSVSettings | DataBaseSettings\n</code></pre> <p>Because pydantic will be able to understand these structural differences, we are able to change our config file accordingly. </p> <pre><code>---\nsource: location: data/some-local-data.csv\n---\nsource: schema: my-schema\ntable: my-table\n</code></pre> <p>When the config is parsed into an instance, the common interface can be leveraged in the code while also providing flexibility in the settings.</p>","tags":["Python","Config Files"]},{"location":"blog/posts/2022/pydantic-configs/#reusability","title":"Reusability","text":"<p>If there are multiple configuration files required for a project, there will often be overlapping configuration elements. By structuring the code in the hierarchical manner, different classes can be reused in order to simplify our interface.</p> <pre><code>class RunConfig(BaseModel): \n\"\"\"Running and saving off a model.\"\"\"\ninput_settings: InputSettings\nmodel_settings: ModelSettings\nresults: ResultsLocation\nclass InterpretationConfig(BaseModel): \n\"\"\"Loading and interpreting model.\"\"\"\nresults: ResultsLocation\n</code></pre> <p>The <code>ResultsLocation</code> class might be useful in multiple configuration files here because it is used to both save and load data.</p>","tags":["Python","Config Files"]},{"location":"blog/posts/2022/pydantic-configs/#limiting-options","title":"Limiting Options","text":"<p>If you want to limit options a variable can take, an <code>enum.Enum</code> type can be used to enforce only a set number of choices.</p> <p>This provides some checking at config parsing time which can give you some quick feedback.</p> <pre><code>from enum import Enum \nclass Difficulties(Enum): \nEASY: str = \"easy\"\nMEDIUM: str = \"medium\"\nHARD: str = \"hard\"\nclass Config(BaseModel): \ndifficulty: Difficulties\n</code></pre> <p>Or like the other example above, a union of types can be expressed.</p>","tags":["Python","Config Files"]},{"location":"blog/posts/2022/pydantic-configs/#additional-validation","title":"Additional Validation","text":"<p>Pydantic provides a bunch of additional data validation which can provide some runtime checks to your configuration.</p> <p>If you are used to using dataclasses too, the dataclasses submodule can be very helpful in order to add some additional checks on the configs at runtime as well.</p> <pre><code>from pydantic.dataclasses import dataclass\n@dataclass\nclass ResultSettings: \nresults_dir: Path\nfile_name: str \noverride: bool = False\ndef __post_init__(self) -&gt; None: \nif not self.results_dir.exists(): \nself.results_dir.mkdir()\nsave_location = self.results_dir / self.file_name\nif save_location.exists() and not override: \nmsg = f\"The results already exists. Not running {save_location}\" \nraise ValueError(msg)\n</code></pre>","tags":["Python","Config Files"]},{"location":"blog/posts/2022/pydantic-configs/#class-implementation","title":"Class Implementation","text":"<p>I often add a lightweight class implementation when working with YAML configs. The goal here is to add an additional method to the pydantic <code>BaseModel</code> in order to easily load different config files.</p> yaml_base_model.py<pre><code>from pydantic import BaseModel\nimport yaml\nfrom pathlib import Path\nclass YamlBaseModel(BaseModel)\n@classmethod\ndef from_yaml(cls, file: str | Path) -&gt; YamlBaseModel: \nfile = Path(file)\nwith open(file, \"r\") as f: \ndata = yaml.safe_load(f)\nreturn cls.parse_obj(data)\n</code></pre> <p>Then when defining a config file, this will be the class inherited from. Making it clear which define the structure of config files and which are just parts of a larger configuration.</p> <pre><code>class ModelSettings(BaseModel): \n\"\"\"Won't be a config file but will be part of some larger configuration.\"\"\"\nfolds: int \nmethod: str\n...\nclass RunConfig(YamlBaseModel):\n\"\"\"Some YAML config file will have this structure.\"\"\"\ninput: InputSettings\nmodel_settings: ModelSettings\n</code></pre> <p>This allows for easy construction of a config object and can be used accordingly.</p> run_script.py<pre><code>if __name__ == \"__main__\": \nconfig = RunConfig.from_yaml(\"./configs/run-config.yaml\")\ndata = config.input.load_data()\n</code></pre> <p>Find the gist of this here with an additional example.</p> <p>Prefer TOML Configs? Can imagine similar support for TOML configs (especially with latest support in python 3.11). Same goes with some additional formats too.</p>","tags":["Python","Config Files"]},{"location":"blog/posts/2022/pydantic-configs/#alternative-comparison","title":"Alternative Comparison","text":"<p>I have an example where: </p> <ol> <li>Some data will be loaded in</li> <li>Some model with configuration is loaded in</li> <li>The model is trained and saves:<ol> <li>Logging information</li> <li>Trained model</li> </ol> </li> </ol> <p>The three implementations will go from worst to best.</p>","tags":["Python","Config Files"]},{"location":"blog/posts/2022/pydantic-configs/#1-hard-coding-constants","title":"1. Hard Coding Constants","text":"<p>This is the worst case implementation since any changes happen to happen in the python file itself. </p> <p>Not only that, but some of the hard-coded values are at the end of the file. That could be hard to sift through if it was a larger file!</p> <pre><code>from my_module import utils, model, data\nif __name__ == \"__main__\": \ndf = data.load_data(\nutils.RAW_DATA_DIR / \"training-data.csv\"\n)\nmy_model_config = {\n...\n}\nmy_model = model.MyModel(**my_model_config)\nmy_model.train(df)\nmy_model.save_logs(\nutils.LOGGING_DIR / \"logging.txt\"\n)\nmy_model.save_model(\nutils.MODEL_DIR / \"my-model.pkl\"\n)\n</code></pre>","tags":["Python","Config Files"]},{"location":"blog/posts/2022/pydantic-configs/#2-using-unstructured-configs","title":"2. Using Unstructured Configs","text":"<p>This introduces a yaml config file which separates all the changing variables from the python file itself. However, it is not totally clear what are all the options available.</p> <p>I do think this is a large improvement though!</p> config.yaml<pre><code>training_data: training-data.csv\nmodel_config: folds: 5\nrandom_seed: 42\n...\nlogging_name: logging.txt\nmodel_name: my-model.pkl\n</code></pre> <pre><code>from typing import Dict, Any\nif __name__ == \"__main__\": \nconfig: Dict[str, Any] = utils.load_config(\"config.yaml\")\ndf = data.load_data(\nutils.RAW_DATA_DIR / config[\"training_data\"]\n)\nmy_model = model.MyModel(**config[\"model_config\"])\nmy_model.train(df)\nmy_model.save_logs(\nutils.LOGGING_DIR / config[\"logging_name\"]\n)\nmy_model.save_model(\nutils.MODEL_DIR / config[\"model_name\"]\n)\n</code></pre>","tags":["Python","Config Files"]},{"location":"blog/posts/2022/pydantic-configs/#3-config-with-pydantic","title":"3. Config with Pydantic","text":"<p>This might be a way to implement with pydantic.</p> my_module/config.py<pre><code>from my_module import utils \nclass Source: \ntraining_data: str \nraw_data: Path = utils.RAW_DATA_DIR\ndef load_data(self) -&gt; pd.DataFrame: \n...\nclass ModelConfig(BaseModel): \nfolds: int = 5\nrandom_seed: int = 42\ndef slugify_config(self, file_base: Path) -&gt; str: \n\"\"\"Helper for file naming.\"\"\"\nclass Artifacts(BaseModel): \nlogging_name: str \nmodel_name: str \nlogging_dir: Path = utils.LOGGING_DIR\nmodel_dir: Path = utils.MODEL_DIR\nclass Config(YamlBaseModel): \ntraining_source: Source\nmodel_config: ModelConfig\nmodel_artifacts: Artifacts \n</code></pre> config.yaml<pre><code>training_source: training_data: training-data.csv\nmodel_config: folds: 10\nrandom_seed: 1\nartifacts: logging_name: logging.txt\nmodel_name: my-model.pkl\n</code></pre> <pre><code>if __name__ == \"__main__\": \nconfig: Config = Config.from_yaml(\"config.yaml\")\ndf = config.source.load_data()\nmy_model = model.MyModel(config.model_config)\nmy_model.fit(df)\nmy_model.save_artifacts(\nconfig.model_config, \nconfig.model_artifacts\n)\n</code></pre> <p>This is clearly the most explicit version of the three. However, there are a lot of benefits for doing so. </p> <ol> <li>Clearly defined configuration leads to: <ol> <li>Known functionality from class definitions</li> <li>Related functionality sticks together</li> </ol> </li> <li>Shorter code in script because:<ol> <li>OOP structuring </li> <li>Ability to work with default values</li> </ol> </li> <li>Able to be extended if desired like: <ol> <li>Better file naming using config information</li> </ol> </li> </ol>","tags":["Python","Config Files"]},{"location":"blog/posts/2022/pydantic-configs/#conclusion","title":"Conclusion","text":"<p>Overall, I've found defining configs with pydantic in mind very useful. It can be super quick to do, provide a lot more structure and understanding to the config settings, and leverage the powerful parsing validation from the library. Give it a try!</p>","tags":["Python","Config Files"]},{"location":"blog/posts/2022/site-setup/","title":"MkDocs and GitHub Pages","text":"<p>This website was created using <code>MkDocs</code>, surrounding python packages like mkdocs-material, and is served with GitHub pages. </p>","tags":["Python","Documentation"]},{"location":"blog/posts/2022/site-setup/#about-mkdocs-and-its-plugins","title":"About MkDocs and its plugins","text":"<p>The MkDocs library makes it easy to create documentation from just markdown and YAML files.</p> <p>With just a few commands, you can quickly iterate with your content and make some great looking webpages.</p> <p>There is also a handful plugin libraries for MkDocs that allow for additional customization. For instance, the theme used here is from the <code>mkdocs-material</code> package. Makes it so easy to have a good looking site on all platforms (especially for people like me who don't make user interfaces often ).</p>","tags":["Python","Documentation"]},{"location":"blog/posts/2022/site-setup/#creating-the-content-and-theme","title":"Creating the Content and Theme","text":"<p>MkDocs really makes it so easy to set up a page. The Getting Started Section allows you to get started.</p> <p>The simpliest project setup will just be two files: </p> <p> </p> <p>The themes and capabilities were inspired from the mkdocs-material site and exploring its mkdocs.yml helped implement mine.</p>","tags":["Python","Documentation"]},{"location":"blog/posts/2022/site-setup/#serving-with-github-pages","title":"Serving with GitHub Pages","text":"<p>GitHub allows you to set up a site for free. If the repo is named <code>&lt;username&gt;.github.io</code>, then it will be hosted at <code>https://&lt;username&gt;.github.io</code>. </p> <p>Tip</p> <p>If you deploy with GitHub pages in any other repo, the docs with be hosted at <code>https://&lt;username&gt;.github.io/&lt;repo-name&gt;</code>. Super cool and would like to use in the future to make quick project documentation!</p> <p>All the code to create this site is on my GitHub here.</p>","tags":["Python","Documentation"]},{"location":"blog/posts/2022/site-setup/#github-action","title":"GitHub Action","text":"<p>The mkdocs-material documentation has the steps in order to set up your GitHub Action for deploy. Those steps are found here.</p>","tags":["Python","Documentation"]},{"location":"blog/posts/2022/site-setup/#github-page-settings","title":"GitHub Page Settings","text":"<p>I had some hiccups while setting up the site. Initially, only my README was being served at https://wd60622.github.io. However, the default \"Deploy from a branch\" setting in the GitHub Pages section was on the <code>main</code> branch which only had the README. </p> <p>Note</p> <p>Running <code>mkdocs gh-deploy</code> pushes all the html files to <code>gh-pages</code> branch in my repo so that branch needed to be selected in the Settings.</p> <p>Below are Settings section that worked for my deployment.</p> <p></p>","tags":["Python","Documentation"]},{"location":"blog/posts/2022/site-setup/#helpful-links","title":"Helpful Links","text":"<p>I found these links helpful while setting up this site and writing this post.</p> <ul> <li>MkDocs</li> <li>MkDocs Material</li> <li>GitHub Pages</li> </ul>","tags":["Python","Documentation"]},{"location":"blog/posts/2023/conjugate-priors/","title":"Conjugate Priors","text":"<p>Bayesian statistics is a great way to think about data under the uncertainty of model parameters and I've found conjugate priors to be a good way to get started with some problems. </p>","tags":["Python","Bayesian Statistics"]},{"location":"blog/posts/2023/conjugate-priors/#what-is-a-conjugate-prior","title":"What is a Conjugate Prior?","text":"<p>A conjugate prior is a prior distribution that is in the same family as the posterior distribution. This is a mathematic convenience that makes it easier to calculate the posterior distribution, often just with a simple addition to the parameters of the prior distribution using the observed data. </p> <p>For instance, if we have a Bernoulli distribution with a single unknown success rate, a Beta prior on the success rate results in a posterior distribution that is also a Beta distribution. The posterior distribution is just the prior distribution with the addition of the number of successes and failures.</p> Get Posterior Distribution of Bernoulli Distribution with Beta Prior<pre><code>from conjugate.distributions import Beta\nfrom conjugate.models import binomial_beta\nN = 10\nX = 4\nprior = Beta(alpha=1, beta=1)\nposterior: Beta = binomial_beta(n=N, x=X, beta_prior=prior)\n</code></pre> <p>Often times as well, the posterior predictive distribution in in a closed form distribution too. This provides new, alternative data sets. For instance, the posterior predictive distribution of a Bernoulli distribution with a Beta prior is a Beta-Binomial distribution.</p> Get Posterior Predictive Distribution of Bernoulli Distribution with Beta Prior<pre><code>from conjugate.distributions import BetaBinomial\nfrom conjugate.models import binomial_beta_posterior_predictive\nposterior_predictive: BetaBinomial = binomial_beta_posterior_predictive(\nn=N, \nbeta=posterior\n) \n</code></pre> <p>Having a closed form distribution for the posterior distribution and posterior predictive distribution can be useful to quickly assess the data, make decisions, and communicate more than just a parameter point estimate.</p> <p>Tip</p> <p>The prior predictive distribution is also a Beta-Binomial distribution. Just the posterior predictive with prior info. This provides the results we expect to see before we see the actual data.</p> <p>Below is visualization of 10 trials, before and after we see the data.</p> <p></p>","tags":["Python","Bayesian Statistics"]},{"location":"blog/posts/2023/conjugate-priors/#common-conjugate-models","title":"Common Conjugate Models","text":"<p>Many common distributions like the Bernoulli, Poisson, or Normal distributions have conjugate models. They show up a lot in the single parameter distributions or where all but one parameter is known. </p> <p>Wikipedia provides table of common conjugate models here.</p>","tags":["Python","Bayesian Statistics"]},{"location":"blog/posts/2023/conjugate-priors/#reducing-problem-to-a-conjugate-model","title":"Reducing Problem to a Conjugate Model","text":"<p>Some data problems scream out these common distributions. For instance,</p> <ul> <li>Count data can be modeled with a Poisson distribution</li> <li>Binary data can be modeled with a Bernoulli distribution</li> <li>Number of successes / single outcomes in a fixed number of trials / attempts can be modeled with a Binomial distribution</li> <li>Sum of independent identical distributed variables can be modeled with a Normal distribution</li> </ul> <p>If not, many questions on the data can be reduced to one of these common distributions. </p> <p>For instance, binning data into two groups can be modeled with a Bernoulli or Binomial distribution. This can be helpful in understanding the tail of a distribution. </p> <p>Knowing common relationships between distributions are useful to understand as well. </p>","tags":["Python","Bayesian Statistics"]},{"location":"blog/posts/2023/conjugate-priors/#why-use-conjugate-priors","title":"Why Use Conjugate Priors?","text":"<p>Conjugate priors can be a starting point due to their simplicity.</p> <p>The availability of quantiles and moments can be useful to understand the data, even if the observed data falls outside of the posterior and posterior predictive distributions.</p> <p>They can give a sense of fit or the lack of.</p>","tags":["Python","Bayesian Statistics"]},{"location":"blog/posts/2023/conjugate-priors/#using-conjugate-priors-in-different-settings","title":"Using Conjugate Priors in Different Settings","text":"<p>Since there is a closed for the posterior distribution, these models could also be implemented in SQL and moments could be calculated in SQL as well. This could be useful for large datasets that are too large to fit in memory and could be useful for a quick analysis backed with statistical theory.</p> <p>Though these distributions are simple, they can be applied at a very granular level. For instance, a single user's click through rate could be modeled with a Bernoulli distribution. This could be useful to understand the uncertainty of a single user's click through rate. A quick win for user level personalization could be to show the user the content with the highest posterior predictive distribution. Or, some relevant reward function could be used to determine the best content to show the user.</p>","tags":["Python","Bayesian Statistics"]},{"location":"blog/posts/2023/conjugate-priors/#summary","title":"Summary","text":"<p>Conjugate priors are a great way to get started with Bayesian statistics. They provide a closed form posterior distribution and, often, posterior predictive distribution. This can be useful to understand the data and make decisions.</p> <p>They are good for simple models and can be applied at a granular level.</p> <p>If you're interested in trying out in python or want to see more examples, check out my repo and docs to use conjugate priors. </p>","tags":["Python","Bayesian Statistics"]},{"location":"blog/posts/2023/extending-pandas/","title":"Extending Pandas","text":"<p>Here is a quick way to make your functionality with pandas objects just as common as using pandas itself and help promote readable code. </p> <p>Our goal here is to make a function that can be used on a pandas object via a self defined attribute. </p> <pre><code>import pandas as pd\nimport my_module\ndf = pd.DataFrame(...)\n# Using user defined boot attribute with its get_samples method\ndf_bootstrap: pd.DataFrame = df.boot.get_samples(my_func, B=100)\n</code></pre>","tags":["Python","Pandas","Data Analysis"]},{"location":"blog/posts/2023/extending-pandas/#implementation","title":"Implementation","text":"<p>In order to do this, we need to create a class that extends the pandas object. This is done by using the <code>pd.api.extensions.register_dataframe_accessor</code> decorator. The name we pass will be the name of the attribute we use to access the functionality.</p> <p>Below creates a functions that will bootstrap a function on a DataFrame and will define the <code>boot</code> attribute on a DataFrame with the <code>BootAccessor</code> class. There the bootstrap function is defined as a method on the class.</p> <pre><code>import pandas as pd\ndef bootstrap(df: pd.DataFrame, b_func, B: int = 100) -&gt; pd.DataFrame: \n\"\"\"Bootstrap a function on a DataFrame. \n    Adds sample index to the result.\n    Args:\n        df (pd.DataFrame): DataFrame to bootstrap\n        b_func (Callable): Function to bootstrap\n        B (int, optional): Number of bootstrap samples. Defaults to 100.\n    Returns:\n        pd.DataFrame: DataFrame of bootstrap samples\n    \"\"\"\nreturn pd.concat([\ndf\n.sample(frac=1, replace=True)\n.pipe(b_func)\n.rename(i)\n.to_frame() \nfor i in range(B)\n], axis=1).T\n@pd.api.extensions.register_dataframe_accessor(\"boot\")\nclass BootAccessor: \ndef __init__(self, pandas_obj):\nself._obj = pandas_obj\ndef get_samples(self, b_func, B: int = 100) -&gt; pd.DataFrame: \n\"\"\"Bootstrap a function on a DataFrame\n        Args:\n            b_func (Callable): Function to bootstrap\n            B (int, optional): Number of bootstrap samples. Defaults to 100.\n        Returns:\n            pd.DataFrame: DataFrame of bootstrap samples\n        \"\"\"\nreturn bootstrap(self._obj, b_func=b_func, B=B)\n</code></pre>","tags":["Python","Pandas","Data Analysis"]},{"location":"blog/posts/2023/extending-pandas/#usage","title":"Usage","text":"<p>After import of this module, you can use the <code>boot</code> accessor on any pandas object.</p> <pre><code>import pandas as pd\ndf = pd.DataFrame(...)\ntry: \ndf.boot\nexcept AttributeError: \npass\nimport my_module\ndef my_func(df: pd.DataFrame) -&gt; pd.Series: \n\"\"\"Function to bootstrap\n    Args:\n        df (pd.DataFrame): DataFrame to bootstrap\n    Returns:\n        pd.Series: mean of the columns\n    \"\"\"\nreturn df.mean()\ndf.boot.get_samples(b_func=my_func, B=100)\n</code></pre> <p>Though is just a single method, this technique can be used to package up a lot of functionality.</p>","tags":["Python","Pandas","Data Analysis"]},{"location":"blog/posts/2023/extending-pandas/#adding-validation","title":"Adding Validation","text":"<p>The <code>BootAccessor</code> class can be extended to add validation to the DataFrame before the bootstrap is performed. This can be good for checking that the DataFrame has the correct columns or that the values are in the correct range -- or anything else for the use case.</p> <pre><code>@pd.api.extensions.register_dataframe_accessor(\"boot\")\nclass BootAccessor: \ndef __init__(self, pandas_obj):\nself._validate(pandas_obj)\nself._obj = pandas_obj\n@staticmethod\ndef _validation(df: pd.DataFrame) -&gt; bool: \n\"\"\"Validate DataFrame\n        Args:\n            df (pd.DataFrame): DataFrame to validate\n        Returns:\n            bool: True if DataFrame is valid\n        \"\"\"\nreturn True\n</code></pre> <p>A simple addition to add checks to all of your functionality.</p>","tags":["Python","Pandas","Data Analysis"]},{"location":"blog/posts/2023/extending-pandas/#alternatives-conclusion","title":"Alternatives &amp; Conclusion","text":"<p>Using the <code>pipe</code> method on pandas objects is great way to make some readable code, but it can quickly become a bit verbose with imports.</p> <pre><code>from my_module import bootstrap, preprocess_func, postprocess_func, plot_timeseries\ndf = pd.DataFrame(...)\ndf_result = (\ndf\n.pipe(preprocess_func, ...)\n.pipe(bootstrap, b_func=my_func, B=100)\n.pipe(postprocess_func, ...)\n.pipe(plot_timeseries, ...)\n</code></pre> <p>An alternative might look like this</p> <pre><code>import my_module\ndf_result = (\ndf\n.transformations.preprocess(...)\n.boot.get_samples(b_func=b_func, B=100)\n.transformations.postprocess(...)\n.plotting.timeseries(...)\n)\n</code></pre> <p>All in all, it's a quick change to add new functionality the widely used data type and maybe help the user experience.</p>","tags":["Python","Pandas","Data Analysis"]},{"location":"blog/posts/2023/extending-pandas/#resources","title":"Resources","text":"<ul> <li>Pandas User Guide: Extending Pandas</li> <li><code>pandas-bootstrap</code> package</li> </ul>","tags":["Python","Pandas","Data Analysis"]},{"location":"blog/posts/2023/iteration-pattern/","title":"Iteration Pattern","text":"<p>Make use of python iteration for more generalized code and functionality</p> <pre><code>for value in iterable: \nprocess(value)\n</code></pre>","tags":["Design Patterns","Python","Data Analysis"]},{"location":"blog/posts/2023/iteration-pattern/#allowing-iteration-in-python","title":"Allowing iteration in python","text":"<p>Objects can be used in <code>for</code> loop as long as the object is iterable or has a way to iterate over it.</p> <p>This functionality can be defined with with the <code>__iter__</code> and <code>__next__</code> method or a generator. </p>","tags":["Design Patterns","Python","Data Analysis"]},{"location":"blog/posts/2023/iteration-pattern/#1-generator-function","title":"1. Generator Function","text":"<p>A generator is a function that returns an iterator. This is done by using the <code>yield</code> keyword instead of <code>return</code>.</p> Example of generator<pre><code>def generator(): \nyield 1\nyield 2\nyield 3\ndef same_generator(): \nfor i in range(1, 4): \nyield i\nfor value in generator():\nprint(value)\n</code></pre> <pre><code>1\n2\n3\n</code></pre> <p>Note</p> <p>Iterators are pretty common in python. i.e. <code>range</code> is an iterator.</p> <p>Alternatives</p> <p>The <code>yield from</code> keyword can be used as an alternative to yield all values from another iterator.</p> Example of yield from<pre><code>def generator(): \nyield from range(1, 4)\n</code></pre> <p>Another way to created a generator is with a generator expression.</p> Example of generator expression<pre><code>generator = (i for i in range(1, 4))\nfor value in generator: \nprint(value)\n</code></pre>","tags":["Design Patterns","Python","Data Analysis"]},{"location":"blog/posts/2023/iteration-pattern/#2-define-__iter__-and-__next__-methods","title":"2. Define <code>__iter__</code> and <code>__next__</code> methods","text":"<p>The <code>__iter__</code> method returns an iterator object and the <code>__next__</code> method returns the next value in the iterator. The <code>StopIteration</code> exception is raised when there are no more values to return.</p> <p>Note</p> <p>The class variables can be used to keep track of the current value and the max value.</p> Example of __iter__ and __next__ method<pre><code>class Iterator: \ndef __init__(self, max_value): \nself.max_value = max_value\nself.current_value = 0\ndef __iter__(self): \nreturn self\ndef __next__(self): \nif self.current_value &gt;= self.max_value: \nraise StopIteration\nself.current_value += 1\nreturn self.current_value\nfor value in Iterator(3):\nprint(value)\n</code></pre> <pre><code>1\n2\n3\n</code></pre> <p>Note</p> <p>The return value of <code>__iter__</code> must be an iterator. This can be done by returning <code>self</code> or by defining a separate iterator class, generator function, or generator expression.</p>","tags":["Design Patterns","Python","Data Analysis"]},{"location":"blog/posts/2023/iteration-pattern/#which-to-use","title":"Which to Use?","text":"<p>Most of the time we are handed different data structures and wouldn't want to override the <code>__iter__</code> method. In this case, we can use generator functions to define the iteration method. </p> Sample Data Structure Handed to Us<pre><code>from dataclasses import dataclass\n@dataclass\nclass Matrix: \ndata: list[list[int]]\ndef __post_init__(self) -&gt; None: \nassert self.nrows &gt; 0, \"Matrix must have at least one row\"\nassert self.ncols &gt; 0, \"Matrix must have at least one column\"\n# Matrix must be rectangular\nassert all(len(row) == self.ncols for row in self.data), \"Matrix must be rectangular\"\n@property \ndef nrows(self) -&gt; int: \nreturn len(self.data)\n@property \ndef ncols(self) -&gt; int: \nreturn len(self.data[0])\n</code></pre> <p>Defining iteration outside of the object allows us to define different iteration methods. Any way we want to iterate over the matrix can be defined as a generator.</p> <p>Below are three different methods for the <code>Matrix</code> class. </p> <ol> <li>Row First</li> <li>Column First</li> <li>Diagonal</li> </ol> Define Iteration Methods<pre><code>def row_first_iteration(matrix: Matrix): \nfor row in matrix.data: \nfor value in row: \nyield value \ndef column_first_iteration(matrix: Matrix): \nfor col in range(matrix.ncols): \nfor row in range(matrix.nrows): \nyield matrix.data[row][col]\ndef diagonal_iteration(matrix: Matrix): \n\"\"\"Iterate through the matrix diagonally. \n    Starts with the top left corner first and goes diagonally up.\n    \"\"\"\nnrows = matrix.nrows\nncols = matrix.ncols\nndiags = ncols + nrows - 1\nfor diag in range(n_diags):\nfor col in range(diag + 1): \nrow = diag - col\nif row &lt; nrows and col &lt; ncols: \nyield matrix.data[row][col]\n</code></pre> <p>Now when we want to iterate over the matrix, we can choose which iteration method to use depending on the use case.</p> Example Usage<pre><code>data = [\n[1, 2],\n[3, 4], \n[5, 6], \n[7, 8]\n]\nmatrix = Matrix(data)\nrow_first_iter = row_first_iteration(matrix)\ncolumn_first_iter = column_first_iteration(matrix)\ndiag_iter = diagonal_iteration(matrix)\nimport pandas as pd \ndf = pd.DataFrame({\n\"Row First\": list(row_first_iter),\n\"Column First\": list(column_first_iter),\n\"Diagonal\": list(diag_iter)\n})\ndf.index.name = \"Iteration\"\n</code></pre> <pre><code>           Row First  Column First  Diagonal\nIteration                                   \n0                  1             1         1\n1                  2             3         3\n2                  3             5         2\n3                  4             7         5\n4                  5             2         4\n5                  6             4         7\n6                  7             6         6\n7                  8             8         8\n</code></pre> <p>The <code>for</code> loop will be the same regardless of how we want to process the values:</p> Various ways to process values<pre><code>process = print\niterable = row_first_iter \nfor value in iterable:\nprocess(value)\n# Alternative iteration and processing\ndef log_value_somewhere(value): \nprint(f\"Logging value {value}\")\nprocess = log_value_somewhere\niterable = diag_iter\nfor value in iterable: \nprocess(value)\n</code></pre> <p>This can be useful when we want to process the values in different ways, but also from different data structures. </p> Example of different data structures<pre><code>import numpy as np\nmatrix_np = np.array(data)\niterable = iter(matrix_np.flatten())\nfor value in iterable: \nprocess(value)\n</code></pre>","tags":["Design Patterns","Python","Data Analysis"]},{"location":"blog/posts/2023/iteration-pattern/#summary","title":"Summary","text":"<p>Classes are often handed to next user so it useful to define iteration methods outside of the class. Not only that, but what is done with the value is separated from the iteration method as well. That is, separation of: </p> <ol> <li>Data </li> <li>Iteration of data</li> <li>Processing of data</li> </ol> <p>This provides flexibility while keeping the code in a consistent format.</p> <pre><code>for value in iterable: \nprocess(value)\n</code></pre>","tags":["Design Patterns","Python","Data Analysis"]},{"location":"blog/posts/2023/iteration-pattern/#references","title":"References","text":"<ul> <li>Python Generators</li> <li><code>__iter__</code> and <code>__next__</code></li> </ul>","tags":["Design Patterns","Python","Data Analysis"]},{"location":"blog/","title":"Blog Posts","text":"<p>Here are some things that I've found interesting and have written about.</p>"},{"location":"blog/#bayesian-statistics","title":"Bayesian Statistics","text":"<ul> <li>Conjugate Priors</li> </ul>"},{"location":"blog/#config-files","title":"Config Files","text":"<ul> <li>Pydantic for Configs</li> </ul>"},{"location":"blog/#data-analysis","title":"Data Analysis","text":"<ul> <li>Extending Pandas</li> <li>Iteration Pattern</li> </ul>"},{"location":"blog/#design-patterns","title":"Design Patterns","text":"<ul> <li>Iteration Pattern</li> </ul>"},{"location":"blog/#documentation","title":"Documentation","text":"<ul> <li>MkDocs and GitHub Pages</li> </ul>"},{"location":"blog/#pandas","title":"Pandas","text":"<ul> <li>Extending Pandas</li> </ul>"},{"location":"blog/#python","title":"Python","text":"<ul> <li>My Favorite Python builtin: pathlib</li> <li>Pydantic for Configs</li> <li>MkDocs and GitHub Pages</li> <li>Conjugate Priors</li> <li>Extending Pandas</li> <li>Iteration Pattern</li> </ul>"},{"location":"blog/#standard-library","title":"Standard Library","text":"<ul> <li>My Favorite Python builtin: pathlib</li> </ul>"}]}